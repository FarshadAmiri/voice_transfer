{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cffe95f",
   "metadata": {},
   "source": [
    "## Download Models Manually\n",
    "\n",
    "To download all models at once without running inference:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38d39fe",
   "metadata": {},
   "source": [
    "## Model Downloads\n",
    "\n",
    "The following models will be auto-downloaded on first run:\n",
    "- **Plachta/Seed-VC**: Main voice conversion models (~1GB)\n",
    "- **funasr/campplus**: Speaker embedding model\n",
    "- **nvidia/bigvgan_v2_22khz_80band_256x**: Vocoder for speech\n",
    "- **nvidia/bigvgan_v2_44khz_128band_512x**: Vocoder for singing\n",
    "- **lj1995/VoiceConversionWebUI**: F0 (pitch) extraction\n",
    "- **openai/whisper-small** or **whisper-base**: Speech tokenizer\n",
    "\n",
    "Models are cached in: `./checkpoints/` and `~/.cache/huggingface/`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e90f22",
   "metadata": {},
   "source": [
    "## Model Requirements by Use Case\n",
    "\n",
    "### For Speech Conversion Only:\n",
    "✅ **Required:**\n",
    "- Plachta/Seed-VC base model\n",
    "- funasr/campplus (speaker embedding)\n",
    "- nvidia/bigvgan_v2_22khz (vocoder)\n",
    "- openai/whisper-small (speech features)\n",
    "- lj1995/VoiceConversionWebUI/rmvpe (F0 extraction)\n",
    "\n",
    "❌ **Can Skip:**\n",
    "- Seed-VC F0 model\n",
    "- nvidia/bigvgan_v2_44khz\n",
    "\n",
    "### For Singing Voice Conversion:\n",
    "✅ **All models required** - Cannot skip any\n",
    "\n",
    "**Total Size:**\n",
    "- Speech only: ~1.5-2 GB\n",
    "- Speech + Singing: ~2-3 GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26231fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download all models manually (run this once)\n",
    "from huggingface_hub import hf_hub_download\n",
    "import os\n",
    "\n",
    "os.makedirs(\"./checkpoints\", exist_ok=True)\n",
    "\n",
    "print(\"Downloading models...\")\n",
    "\n",
    "# 1. Main Seed-VC models\n",
    "print(\"\\n1. Downloading Seed-VC base model...\")\n",
    "hf_hub_download(\n",
    "    repo_id=\"Plachta/Seed-VC\",\n",
    "    filename=\"DiT_seed_v2_uvit_whisper_small_wavenet_bigvgan_pruned.pth\",\n",
    "    cache_dir=\"./checkpoints\"\n",
    ")\n",
    "hf_hub_download(\n",
    "    repo_id=\"Plachta/Seed-VC\",\n",
    "    filename=\"config_dit_mel_seed_uvit_whisper_small_wavenet.yml\",\n",
    "    cache_dir=\"./checkpoints\"\n",
    ")\n",
    "\n",
    "print(\"2. Downloading Seed-VC F0 model...\")\n",
    "hf_hub_download(\n",
    "    repo_id=\"Plachta/Seed-VC\",\n",
    "    filename=\"DiT_seed_v2_uvit_whisper_base_f0_44k_bigvgan_pruned_ft_ema.pth\",\n",
    "    cache_dir=\"./checkpoints\"\n",
    ")\n",
    "hf_hub_download(\n",
    "    repo_id=\"Plachta/Seed-VC\",\n",
    "    filename=\"config_dit_mel_seed_uvit_whisper_base_f0_44k.yml\",\n",
    "    cache_dir=\"./checkpoints\"\n",
    ")\n",
    "\n",
    "# 2. CAMPPlus speaker embedding\n",
    "print(\"3. Downloading CAMPPlus model...\")\n",
    "hf_hub_download(\n",
    "    repo_id=\"funasr/campplus\",\n",
    "    filename=\"campplus_cn_common.bin\",\n",
    "    cache_dir=\"./checkpoints\"\n",
    ")\n",
    "\n",
    "# 3. RMVPE for F0 extraction\n",
    "print(\"4. Downloading RMVPE model...\")\n",
    "hf_hub_download(\n",
    "    repo_id=\"lj1995/VoiceConversionWebUI\",\n",
    "    filename=\"rmvpe.pt\",\n",
    "    cache_dir=\"./checkpoints\"\n",
    ")\n",
    "\n",
    "# 4. BigVGAN vocoders (these are large!)\n",
    "print(\"5. Downloading BigVGAN 22kHz model...\")\n",
    "from modules.bigvgan import bigvgan\n",
    "bigvgan_22k = bigvgan.BigVGAN.from_pretrained('nvidia/bigvgan_v2_22khz_80band_256x')\n",
    "\n",
    "print(\"6. Downloading BigVGAN 44kHz model...\")\n",
    "bigvgan_44k = bigvgan.BigVGAN.from_pretrained('nvidia/bigvgan_v2_44khz_128band_512x')\n",
    "\n",
    "# 5. Whisper models\n",
    "print(\"7. Downloading Whisper models...\")\n",
    "from transformers import WhisperModel, AutoFeatureExtractor\n",
    "whisper_small = WhisperModel.from_pretrained(\"openai/whisper-small\")\n",
    "whisper_base = WhisperModel.from_pretrained(\"openai/whisper-base\")\n",
    "\n",
    "print(\"\\n✓ All models downloaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8eb867d",
   "metadata": {},
   "source": [
    "## Check what models are already cached locally\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72895cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "checkpoints_dir = Path(\"./checkpoints\")\n",
    "hf_cache = Path.home() / \".cache\" / \"huggingface\"\n",
    "\n",
    "print(\"Local checkpoints folder:\")\n",
    "if checkpoints_dir.exists():\n",
    "    for item in checkpoints_dir.rglob(\"*.pth\"):\n",
    "        print(f\"  {item}\")\n",
    "    for item in checkpoints_dir.rglob(\"*.bin\"):\n",
    "        print(f\"  {item}\")\n",
    "    for item in checkpoints_dir.rglob(\"*.pt\"):\n",
    "        print(f\"  {item}\")\n",
    "else:\n",
    "    print(\"  (not created yet)\")\n",
    "\n",
    "print(f\"\\nHugging Face cache: {hf_cache}\")\n",
    "print(f\"Cache exists: {hf_cache.exists()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5213f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
